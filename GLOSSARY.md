# Metrics Glossary

This glossary defines all metrics used in the customer churn prediction project to ensure consistent terminology across all documentation, code, and stakeholder communication.

---

## Customer Metrics

### Customers Identified (True Positives - TP)
- **Value:** 348
- **Definition:** Number of actual churners correctly flagged by the model
- **Formula:** True Positives from confusion matrix
- **Business Meaning:** These are customers who were going to churn AND the model correctly identified them
- **Important:** This is NOT the same as "customers saved"

### Customers Saved
- **Value:** 226
- **Definition:** Number of churners who were retained through successful intervention campaigns
- **Formula:** `Customers Identified × Campaign Success Rate = 348 × 0.65 = 226`
- **Business Meaning:** Out of 348 identified churners, we successfully retained 226 (65% success rate)
- **Why 65%?** Industry-standard retention campaign success rate (conservative estimate)

### Customers Lost (False Negatives - FN)
- **Value:** 26
- **Definition:** Actual churners that the model failed to identify
- **Formula:** False Negatives from confusion matrix
- **Business Meaning:** These customers churned and we didn't see it coming
- **False Negative Rate:** `FN / (TP + FN) = 26 / (348 + 26) = 6.95% ≈ 7%`

### False Alarms (False Positives - FP)
- **Value:** 503
- **Definition:** Non-churners incorrectly flagged as at-risk
- **Formula:** False Positives from confusion matrix
- **Business Meaning:** We ran retention campaigns on these customers unnecessarily
- **Cost Impact:** Wasted campaign costs, but prevents bigger losses

### True Negatives (TN)
- **Value:** 532
- **Definition:** Non-churners correctly identified as not at risk
- **Formula:** True Negatives from confusion matrix
- **Business Meaning:** Customers we correctly left alone (no action needed)

---

## Campaign Metrics

### Total Campaigns Run
- **Value:** 851
- **Definition:** Total number of retention campaigns executed
- **Formula:** `TP + FP = 348 + 503 = 851`
- **Business Meaning:** Every customer flagged as at-risk receives a campaign (both correct and false alarms)
- **Why include FP?** We don't know they're false alarms until AFTER the campaign

### Campaign Cost per Customer
- **Value:** $100
- **Definition:** Cost to run one retention campaign (call center, discounts, offers)
- **Source:** Config parameter (industry average)
- **Configurable:** See `config.RETENTION_COST`

### Total Campaign Cost
- **Value:** $85,100
- **Definition:** Total cost of running all retention campaigns
- **Formula:** `Total Campaigns × Cost per Campaign = 851 × $100 = $85,100`
- **Includes:** Both successful campaigns (TP) AND wasted campaigns (FP)

### Campaign Success Rate
- **Value:** 65%
- **Definition:** Probability that a retention campaign successfully retains an at-risk customer
- **Source:** Industry benchmark (conservative estimate)
- **Configurable:** Can be adjusted based on A/B test results
- **Sensitivity:** ROI analysis shows project remains profitable even at 40-85% success rates

---

## Financial Metrics

### Customer Lifetime Value (CLV)
- **Value:** $2,000
- **Definition:** Average revenue generated by a customer over their entire relationship
- **Source:** Config parameter (telecom industry average)
- **Configurable:** See `config.CUSTOMER_LIFETIME_VALUE`
- **Sensitivity:** ROI remains strong from $1,000 to $3,000

### Churn Cost
- **Value:** $1,500
- **Definition:** Cost of losing a customer (CLV minus acquisition cost)
- **Formula:** `CLV - Acquisition Cost ≈ $2,000 - $500 = $1,500`
- **Source:** Config parameter
- **Configurable:** See `config.CHURN_COST`

### Revenue Saved
- **Value:** $452,400
- **Definition:** Total revenue preserved by successfully retaining customers
- **Formula:** `Customers Saved × CLV = 226 × $2,000 = $452,400`
- **Business Meaning:** This revenue would have been lost without the model

### Net Benefit (Net Savings)
- **Value:** $367,300
- **Definition:** Profit after subtracting all campaign costs from revenue saved
- **Formula:** `Revenue Saved - Total Campaign Cost = $452,400 - $85,100 = $367,300`
- **Business Meaning:** Bottom-line impact on annual revenue

### ROI (Return on Investment)
- **Value:** 431.6%
- **Definition:** Percentage return on every dollar spent on retention campaigns
- **Formula:** `(Net Benefit / Total Campaign Cost) × 100 = ($367,300 / $85,100) × 100 = 431.6%`
- **Business Meaning:** For every $1 spent, we get back $5.32
- **ROI Multiple:** `(431.6% + 100%) / 100 = 5.316 ≈ $5.32 per dollar`

### Baseline Loss (Without Model)
- **Value:** $748,000
- **Definition:** Revenue loss if we had no model and all churners left
- **Formula:** `(TP + FN) × CLV = (348 + 26) × $2,000 = $748,000`
- **Business Meaning:** What we would lose doing nothing

### Actual Loss (With Model)
- **Value:** $380,700
- **Definition:** Revenue loss even with the model (failed campaigns + missed churners)
- **Formula:** `(FN × CLV) + (TP × (1 - Success Rate) × CLV) + Campaign Cost`
- **Components:**
  - Missed churners: `26 × $2,000 = $52,000`
  - Failed campaigns: `348 × 0.35 × $2,000 = $243,600`
  - Campaign cost: `$85,100`
  - Total: `$52,000 + $243,600 + $85,100 = $380,700`

### Savings vs Baseline
- **Value:** $367,300
- **Definition:** How much better we do compared to no model
- **Formula:** `Baseline Loss - Actual Loss = $748,000 - $380,700 = $367,300`
- **Same as Net Benefit:** Yes, these are equivalent calculations

### Improvement vs Baseline
- **Value:** 49.1%
- **Definition:** Percentage improvement compared to doing nothing
- **Formula:** `(Savings / Baseline Loss) × 100 = ($367,300 / $748,000) × 100 = 49.1%`
- **Business Meaning:** We reduce churn-related losses by nearly half

---

## Model Performance Metrics

### Accuracy
- **Value:** 62.5%
- **Definition:** Percentage of all predictions that were correct (both churn and non-churn)
- **Formula:** `(TP + TN) / Total = (348 + 532) / 1409 = 62.5%`
- **Why Not Higher?** Optimized for recall (catching churners), not overall accuracy

### Precision
- **Value:** 40.9%
- **Definition:** Of customers we flagged, what percentage actually churned
- **Formula:** `TP / (TP + FP) = 348 / (348 + 503) = 40.9%`
- **Business Meaning:** 4 out of 10 flagged customers are true churners
- **Trade-off:** Lower precision is acceptable given high cost of missed churners

### Recall (Sensitivity, True Positive Rate)
- **Value:** 93.0%
- **Definition:** Of all customers who actually churned, what percentage did we catch
- **Formula:** `TP / (TP + FN) = 348 / (348 + 26) = 93.0%`
- **Business Meaning:** We identify 93 out of 100 churners
- **Why Prioritize?** Missing a churner ($1,500 loss) is 15× worse than false alarm ($100)

### F1 Score
- **Value:** ~0.568
- **Definition:** Harmonic mean of precision and recall (balanced metric)
- **Formula:** `2 × (Precision × Recall) / (Precision + Recall)`
- **Use Case:** Good for comparing models, but recall is our primary optimization target

### ROC-AUC (Area Under ROC Curve)
- **Value:** 0.838
- **Definition:** Model's ability to discriminate between churners and non-churners
- **Range:** 0.5 (random) to 1.0 (perfect)
- **Interpretation:** 83.8% chance model ranks a random churner higher than random non-churner
- **95% CI:** [0.814, 0.861]

### False Negative Rate (Miss Rate)
- **Value:** 7.0%
- **Definition:** Percentage of actual churners we failed to identify
- **Formula:** `FN / (TP + FN) = 26 / 374 = 6.95% ≈ 7%`
- **Business Meaning:** We miss only 7 out of 100 churners

### False Positive Rate
- **Value:** 48.6%
- **Definition:** Percentage of non-churners incorrectly flagged
- **Formula:** `FP / (FP + TN) = 503 / (503 + 532) = 48.6%`
- **Why So High?** Trade-off for high recall - acceptable given cost asymmetry

---

## Segment-Specific Terminology

### Tenure
- **Definition:** Number of months a customer has been with the company
- **Segments:**
  - `<12 months`: New customers (0-11 months)
  - `12-24 months`: Early customers (1-2 years)
  - `24-36 months`: Mid customers (2-3 years)
  - `36-48 months`: Established customers (3-4 years)
  - `>48 months`: Loyal customers (4+ years)

### Contract Type
- **Month-to-month:** No commitment, can cancel anytime (highest churn risk)
- **One year:** 12-month contract commitment
- **Two year:** 24-month contract commitment (lowest churn risk)

### Monthly Charges Tiers
- **Low:** $0-35
- **Medium:** $35-70
- **High:** $70-90
- **Very High:** $90+

---

## Common Confusions (IMPORTANT!)

### ❌ WRONG: "Customers Saved" = TP = 348
This assumes **100% campaign success**, which is unrealistic.

### ✅ CORRECT: "Customers Saved" = TP × Success Rate = 226
Only **65%** of retention campaigns succeed.

---

### ❌ WRONG: "Campaign Cost" = TP × $100 = $34,800
This only counts successful identifications, ignoring false alarms.

### ✅ CORRECT: "Campaign Cost" = (TP + FP) × $100 = $85,100
We run campaigns on **ALL flagged customers**, including false positives.

---

### ❌ WRONG: "ROI" ≈ 1,200%+ (using old calculation)
Old calculation: `(TP × CLV - TP × Cost) / (TP × Cost) × 100`

### ✅ CORRECT: "ROI" = 431.6% (using enhanced calculation)
Enhanced: `((TP × Success × CLV) - (TP+FP) × Cost) / ((TP+FP) × Cost) × 100`

---

## Calculation Examples

### Example 1: ROI Calculation
```
Given:
- TP = 348, FP = 503, FN = 26, TN = 532
- CLV = $2,000, Campaign Cost = $100, Success Rate = 65%

Step 1: Total Campaigns
= TP + FP = 348 + 503 = 851

Step 2: Campaign Execution Cost
= 851 × $100 = $85,100

Step 3: Customers Saved
= TP × Success Rate = 348 × 0.65 = 226.2 ≈ 226

Step 4: Revenue Saved
= 226 × $2,000 = $452,400

Step 5: Net Benefit
= $452,400 - $85,100 = $367,300

Step 6: ROI
= ($367,300 / $85,100) × 100 = 431.6%
```

### Example 2: False Negative Rate
```
Given:
- TP = 348, FN = 26

FNR = FN / (TP + FN) = 26 / (348 + 26) = 26 / 374 = 0.0695 = 6.95% ≈ 7%

Interpretation: We miss about 7 out of every 100 churners
```

---

## References

- **Confusion Matrix:** See `outputs/reports/advanced_evaluation_summary.txt`
- **ROI Analysis:** See `outputs/reports/enhanced_roi_analysis.csv`
- **Confidence Intervals:** See `outputs/reports/confidence_intervals.csv`
- **Configuration:** See `src/config.py`
- **Audit Report:** See `SENIOR_DS_AUDIT_REPORT.md`

---

## Version History

- **v1.0** (2025-11-13): Initial glossary created as part of Senior DS audit
- Standardizes terminology across README, code, dashboard, and documentation
- Addresses "Inconsistent Terminology" issue from audit report

---

**Last Updated:** 2025-11-13
**Maintained By:** Data Science Team
**Questions?** Refer to `SENIOR_DS_AUDIT_REPORT.md` Section 1.4
